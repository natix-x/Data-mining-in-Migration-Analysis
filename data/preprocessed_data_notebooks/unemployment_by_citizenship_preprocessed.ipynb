{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b27a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0cd46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../preprocessed_data/unemployment_by_citizenship_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() == 1:\n",
    "        df = df.drop(columns=[col])\n",
    "        \n",
    "if \"unit\" in df.columns and \"Per hundred thousand inhabitants\" in df[\"unit\"].unique():\n",
    "    df = df[df[\"unit\"] == \"Per hundred thousand inhabitants\"]\n",
    "    df = df.drop(columns=[\"unit\"])\n",
    "\n",
    "if \"unit\" in df.columns and (df[\"unit\"] == \"Person\").all():\n",
    "    df = df.drop(columns=[\"unit\"])\n",
    "\n",
    "def remove_euro(row):\n",
    "    return any(value.startswith('Euro') for value in row.astype(str))\n",
    "\n",
    "df = df[~df.apply(remove_euro, axis=1)]\n",
    "\n",
    "def remove_total(row):\n",
    "    return any(value.startswith('Total') for value in row.astype(str))\n",
    "\n",
    "df = df[~df.apply(remove_total, axis=1)]\n",
    "\n",
    "df = df.dropna(subset=[\"OBS_VALUE\"])\n",
    "\n",
    "for col in df.columns:\n",
    "    if \"Foreign country\" in col:\n",
    "        df = df.drop(columns=[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04757e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e84c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ab80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e78da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    unique_vals = df[col].unique()\n",
    "    print(f\"{col}: {unique_vals[:40]}\")\n",
    "    if len(unique_vals) > 40:\n",
    "        print(f\"... and {len(unique_vals) - 40} others\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5522f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc2afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_value_name = None # WYPELNIC\n",
    "if obs_value_name:\n",
    "    df = df.rename(columns={\"OBS_VALUE\": obs_value_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e784382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../initially_processed_data/unemployment_by_citizenship_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size for better visualization\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Create subplots - one for each column (except OBS_VALUE)\n",
    "columns_to_analyze = [col for col in df.columns if col != 'OBS_VALUE']\n",
    "num_columns = len(columns_to_analyze)\n",
    "fig, axes = plt.subplots(num_columns, 1, figsize=(12, 6*num_columns))\n",
    "\n",
    "# For each column, aggregate OBS_VALUE and create a visualization\n",
    "for i, column in enumerate(columns_to_analyze):\n",
    "    # Group by the column and aggregate OBS_VALUE (using mean)\n",
    "    grouped_data = df.groupby(column)['OBS_VALUE'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    # For columns with too many unique values, take top 20\n",
    "    if len(grouped_data) > 20:\n",
    "        grouped_data = grouped_data.head(20)\n",
    "    \n",
    "    # Create the plot\n",
    "    ax = axes[i]\n",
    "    grouped_data.plot(kind='bar', ax=ax)\n",
    "    ax.set_title(f'Average OBS_VALUE by {column}')\n",
    "    ax.set_ylabel('Average OBS_VALUE')\n",
    "    ax.set_xlabel(column)\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ca63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_copy = df.copy()\n",
    "\n",
    "if \"TIME_PERIOD\" in df_copy.columns:\n",
    "    max_time = df_copy[\"TIME_PERIOD\"].max()\n",
    "    df_filtered = df_copy[df_copy[\"TIME_PERIOD\"] == max_time]\n",
    "\n",
    "if \"geo\" in df_filtered.columns and \"OBS_VALUE\" in df_filtered.columns:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df_filtered.groupby(\"geo\")[\"OBS_VALUE\"].mean().sort_values(ascending=False).plot(kind=\"bar\")\n",
    "    plt.title(f\"OBS_VALUE by geo for TIME_PERIOD {{max_time}}\")\n",
    "    plt.ylabel(\"OBS_VALUE\")\n",
    "    plt.xlabel(\"geo\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9959f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aggregated_obs_values = df.groupby(['geo', 'TIME_PERIOD'])['OBS_VALUE'].sum()\n",
    "\n",
    "threshold = 0.25 * df[\"TIME_PERIOD\"].nunique()\n",
    "\n",
    "group = df.groupby('geo')\n",
    "\n",
    "countries_to_remove = []\n",
    "\n",
    "for geo, group_data in group:\n",
    "    time_period_counts = group_data['TIME_PERIOD'].value_counts()\n",
    "    missing_counts = df[\"TIME_PERIOD\"].nunique() - time_period_counts.count()\n",
    "    \n",
    "    if missing_counts > threshold:\n",
    "        countries_to_remove.append(geo)\n",
    "\n",
    "df_copy = df[~df['geo'].isin(countries_to_remove)]\n",
    "aggregated_obs_values = df_copy.groupby(['geo', 'TIME_PERIOD'])['OBS_VALUE'].sum()\n",
    "\n",
    "top_threshold = aggregated_obs_values.groupby('geo').mean().quantile(0.9)\n",
    "top_countries = aggregated_obs_values.groupby('geo').mean()\n",
    "top_countries = top_countries[top_countries > top_threshold].index\n",
    "filtered_top_df = aggregated_obs_values.loc[top_countries].reset_index()\n",
    "\n",
    "bottom_threshold = aggregated_obs_values.groupby('geo').mean().quantile(0.1)\n",
    "bottom_countries = aggregated_obs_values.groupby('geo').mean()\n",
    "bottom_countries = bottom_countries[bottom_countries < bottom_threshold].index\n",
    "filtered_bottom_df = aggregated_obs_values.loc[bottom_countries].reset_index()\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(filtered_top_df, x='TIME_PERIOD', y='OBS_VALUE', color='geo', \n",
    "              markers=True, title='Top 10% Countries by Aggregated OBS_VALUE')\n",
    "fig.show()\n",
    "\n",
    "fig = px.line(filtered_bottom_df, x='TIME_PERIOD', y='OBS_VALUE', color='geo', \n",
    "              markers=True, title='Bottom 10% Countries by Aggregated OBS_VALUE')\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
